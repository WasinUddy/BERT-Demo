{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using BERT\n",
    "An example of using BERT for text classification task using Tensorflow by fine-tuning BERT model to classify movie reviews in the [IMDB dataset](http://ai.stanford.edu/~amaas/data/sentiment/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies \n",
    "\n",
    "- **TensorFlow Text for Natural Language Processing (NLP) tasks**\n",
    "    ```bash\n",
    "    !pip install \"tensorflow-text==2.11.*\"\n",
    "    ```\n",
    "    TensorFlow Text is a powerful library that provides tools for NLP tasks like text classification, sentiment analysis, named entity recognition, etc. It allows preprocessing text data, tokenization, and word embedding, facilitating the creation and training of advanced NLP models.\n",
    "\n",
    "- **TensorFlow/models for utilizing the AdamW optimizer**\n",
    "    ```bash\n",
    "    !pip install \"tf-models-official==2.11.0\"\n",
    "    ```\n",
    "    TensorFlow/models offers official prebuilt models and optimization algorithms. It includes the AdamW optimizer, a variant of Adam that incorporates weight decay for more stable training and improved generalization. This library provides various model implementations and optimization strategies to enhance deep learning model performance.\n",
    "\n",
    "- **TensorFlow Hub to access a wealth of pretrained models**\n",
    "    ```bash\n",
    "    !pip install \"tensorflow_hub\"\n",
    "    ```\n",
    "    TensorFlow Hub hosts a vast collection of pretrained models, embeddings, and modules for tasks like image recognition and text understanding. By leveraging TensorFlow Hub, you can easily integrate state-of-the-art architectures into your projects, saving valuable time and computational resources. It enables you to utilize cutting-edge models without training them from scratch, making it invaluable for machine learning practitioners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/wasin/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: tensorflow-text==2.11.* in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-text==2.11.*) (0.14.0)\n",
      "Requirement already satisfied: tensorflow<2.12,>=2.11.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-text==2.11.*) (2.11.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.56.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.9.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (16.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (23.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.16.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.2.2)\n",
      "/bin/bash: /home/wasin/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: tf-models-official==2.11.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (2.11.0)\n",
      "Requirement already satisfied: Cython in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (3.0.0)\n",
      "Requirement already satisfied: Pillow in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (10.0.0)\n",
      "Requirement already satisfied: gin-config in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (0.5.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (2.94.0)\n",
      "Requirement already satisfied: immutabledict in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (3.0.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (1.5.16)\n",
      "Requirement already satisfied: matplotlib in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (1.24.3)\n",
      "Requirement already satisfied: oauth2client in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (4.1.3)\n",
      "Requirement already satisfied: opencv-python-headless==4.5.2.52 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (4.5.2.52)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (2.0.3)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (9.0.0)\n",
      "Requirement already satisfied: pycocotools in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (2.0.6)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (5.4.1)\n",
      "Requirement already satisfied: sacrebleu in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (2.3.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (1.11.1)\n",
      "Requirement already satisfied: sentencepiece in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (0.1.99)\n",
      "Requirement already satisfied: seqeval in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (1.2.2)\n",
      "Requirement already satisfied: six in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-addons in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (0.21.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (4.9.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (0.14.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (0.7.5)\n",
      "Requirement already satisfied: tensorflow-text~=2.11.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (2.11.0)\n",
      "Requirement already satisfied: tensorflow~=2.11.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (2.11.1)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tf-models-official==2.11.0) (1.1.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.11.0) (0.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.11.0) (2.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.11.0) (0.1.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.11.0) (2.11.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.11.0) (4.1.1)\n",
      "Requirement already satisfied: certifi in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official==2.11.0) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official==2.11.0) (2.8.2)\n",
      "Requirement already satisfied: requests in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official==2.11.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official==2.11.0) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official==2.11.0) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official==2.11.0) (1.26.16)\n",
      "Requirement already satisfied: bleach in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official==2.11.0) (6.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas>=0.22.0->tf-models-official==2.11.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas>=0.22.0->tf-models-official==2.11.0) (2023.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (1.56.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (3.9.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (2.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (23.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (67.8.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow~=2.11.0->tf-models-official==2.11.0) (0.32.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.11.0) (0.1.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->tf-models-official==2.11.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->tf-models-official==2.11.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->tf-models-official==2.11.0) (4.41.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->tf-models-official==2.11.0) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->tf-models-official==2.11.0) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->tf-models-official==2.11.0) (6.0.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from oauth2client->tf-models-official==2.11.0) (0.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from oauth2client->tf-models-official==2.11.0) (0.3.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from oauth2client->tf-models-official==2.11.0) (4.9)\n",
      "Requirement already satisfied: portalocker in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from sacrebleu->tf-models-official==2.11.0) (2.7.0)\n",
      "Requirement already satisfied: regex in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from sacrebleu->tf-models-official==2.11.0) (2023.6.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from sacrebleu->tf-models-official==2.11.0) (0.9.0)\n",
      "Requirement already satisfied: colorama in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from sacrebleu->tf-models-official==2.11.0) (0.4.6)\n",
      "Requirement already satisfied: lxml in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from sacrebleu->tf-models-official==2.11.0) (4.9.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from seqeval->tf-models-official==2.11.0) (1.3.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-addons->tf-models-official==2.11.0) (2.13.3)\n",
      "Requirement already satisfied: array-record in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official==2.11.0) (0.4.0)\n",
      "Requirement already satisfied: click in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official==2.11.0) (8.1.6)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official==2.11.0) (1.3.0)\n",
      "Requirement already satisfied: promise in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official==2.11.0) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official==2.11.0) (1.13.0)\n",
      "Requirement already satisfied: toml in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official==2.11.0) (0.10.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official==2.11.0) (0.38.4)\n",
      "Requirement already satisfied: zipp in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official==2.11.0) (3.16.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.11.0) (1.59.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.11.0) (5.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->kaggle>=1.3.9->tf-models-official==2.11.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->kaggle>=1.3.9->tf-models-official==2.11.0) (3.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.11.0) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.11.0) (3.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official==2.11.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official==2.11.0) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official==2.11.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official==2.11.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official==2.11.0) (2.3.6)\n",
      "Requirement already satisfied: webencodings in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.11.0) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.11.0) (1.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official==2.11.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official==2.11.0) (6.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official==2.11.0) (2.1.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official==2.11.0) (3.2.2)\n",
      "/bin/bash: /home/wasin/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: tensorflow_hub in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_hub) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_hub) (3.19.6)\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow Text for Natural Language Processing (NLP) tasks\n",
    "! pip install \"tensorflow-text==2.11.*\"\n",
    "\n",
    "# Tensorflow/models for utilizing the powerful AdamW optimizer\n",
    "! pip install \"tf-models-official==2.11.0\"\n",
    "\n",
    "# Tensorflow Hub to unlock a plethora of state-of-the-art pretrained models\n",
    "! pip install \"tensorflow_hub\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 00:54:43.557501: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-26 00:54:44.906591: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/wasin/miniconda3/envs/tf/lib/:/home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages/nvidia/cudnn/lib\n",
      "2023-07-26 00:54:44.909064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/wasin/miniconda3/envs/tf/lib/:/home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages/nvidia/cudnn/lib\n",
      "2023-07-26 00:54:44.909081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2070 with Max-Q Design, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "# os and shutil for navigating directories and saving files\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# All tensorflow Gang for Deep Learning\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub    \n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization\n",
    "\n",
    "# Matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Mixed precision training\n",
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Process Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset using tf.keras.utils.get_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84125825/84125825 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.utils.get_file(\n",
    "    'aclImdb.tar.gz',\n",
    "    'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz',\n",
    "    cache_dir='.', cache_subdir='', untar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define path to the dataset for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "\n",
    "# Remove unused folders to use binary classification\n",
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset\n",
    "using `text_dataset_from_directory` to create tf.data.Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 17:28:27.933221: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-25 17:28:28.666794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38245 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:61:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "raw_train_dataset = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',        # directory of the dataset\n",
    "    batch_size=batch_size,  # batch size\n",
    "    validation_split=0.2,   # 20% of the dataset will be used for validation\n",
    "    subset='training',      # training subset of the dataset define what this dataset will be used for\n",
    "    seed=seed               # seed for reproducibility\n",
    ")\n",
    "class_names = raw_train_dataset.class_names\n",
    "train_dataset = raw_train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Load the validation dataset\n",
    "validation_dataset = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed\n",
    ")\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/test',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b\"This is a very sad movie. Really. Nothing happens in this movie. The Script is bad!!! I guess they've just copy-paste the first 15 pages to 90 pages. The Producers must have thought let's create a Hollywood movie here in Belgium. They didn't succeed. Now in the third week it is only running in Antwerp and Brussels at 22h45 or something. In the past we have had really good movies in Belgium, like Daens. Shades is a waste of your time. Maybe you could sneak in the theater after you've seen a real movie. If you've seen 10 minutes of Shades, you've seen it all. It was advertised to death on local radio and TV. I hope it will disappear in the Shades soon.\"\n",
      "Label : 0 (neg)\n",
      "Review: b'Dick Foran and Peggy Moran, who were so good together in THE MUMMY\\'S HAND, return for this very minor Universal Horror offering. But this time, instead of having Wallace Ford as the comedic sidekick \"Babe,\" we get Fuzzy Knight substituting as a silly buddy named \"Stuff\". But the results are nowhere near as charming, and the scare level is virtually nil.<br /><br />Dick is a businessman who gets the idea of spearheading a treasure hunt on a remote island inside a spooky old castle. Peggy is one of the gang who comes along for the ride. But there is a tall and skinny John Carradine lookalike in a black cape and big hat known as \"The Phantom\" who crashes the party in pursuit of the buried fortune himself.<br /><br />This \"phantom\" is not very mysterious, and no effort is made to even try and keep his rather average guy face in the shadows to create any tension or spookiness. It\\'s always nice to see perky Moran, but otherwise you can chalk this up as one of Universal\\'s instantly forgettable misfires.'\n",
      "Label : 0 (neg)\n",
      "Review: b'This Kiyoshi Kurosawa ghost movie is pretty wild, and it did have at least one jump scare that caught me off guard. But all in all, the movie is incredibly stupid, with a detective trying to track down a suspected serial killer, only to find out he may have committed one of the crimes. Then he finds himself haunted by a gorgeous Asian lady ghost, and has no idea why (and neither does the viewer). As other murders are committed, he becomes even more confused as the killers are easily found, and this ghost still haunts him for some reason. Not only is the plot completely stupid, the lady ghost is more funny than anything, especially when she suddenly flies across the city, like Wonder Woman. And the ending makes little sense, in fact, the whole movie makes little sense, and I can\\'t recommend it at all. If it didn\\'t take itself so serious, I would think it was supposed to be a black comedy. Outside of \"Bright Future\" this is the worst movie directed by Kiyoshi Kurosawa I have seen yet.'\n",
      "Label : 0 (neg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 17:28:31.325828: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text, labels in train_dataset.take(1):\n",
    "    for i in range(3):\n",
    "        print(f'Review: {text.numpy()[i]}')\n",
    "        label = labels.numpy()[i]\n",
    "        print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading BERT from the Tensorflow Hub\n",
    "Inorder to fine-tune BERT model we will have to choose the desired BERT model from Tensorflow Hub\n",
    "1. BERT-Base, Uncased and seven more models with trained weights released by the original BERT authors.\n",
    "2. Small BERTs have the same general architecture but fewer and/or smaller Transformer blocks, which lets you explore tradeoffs between speed, size and quality.\n",
    "3. ALBERT: four different sizes of \"A Lite BERT\" that reduces model size (but not computation time) by sharing parameters between layers.\n",
    "4. BERT Experts: eight models that all have the BERT-base architecture but offer a choice between different pre-training domains, to align more closely with the target task.\n",
    "5. Electra has the same architecture as BERT (in three different sizes), but gets pre-trained as a discriminator in a set-up that resembles a Generative Adversarial Network (GAN).\n",
    "6. BERT with Talking-Heads Attention and Gated GELU [base, large] has two improvements to the core of the Transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "# Switch this name to the model you want to use\n",
    "bert_model_name = 'bert_en_uncased_L-12_H-768_A-12' \n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Preprocessing model\n",
    "Inorder for text to be used with BERT text inputs need to be transformed to a numeric token ids and arraged in BERT format Tensors befor inputing to the model. Which is F*** tedious. But thanks to Tensorflow Text we can use the preprocessing model from the BERT model hub module to transform our text inputs to BERT format Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       \t: ['input_word_ids', 'input_type_ids', 'input_mask']\n",
      "Shape      \t: (1, 128)\n",
      "Word Ids   \t: [  101  2023  2003  1996  4485 22199  3185  1045  2031  2412 17886  2046]\n",
      "Input Mask \t: [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Type Ids   \t: [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Try out the preprocessing model\n",
    "text_test = ['this is the shittest movie I have ever digest into my brain']\n",
    "text_preprocessed = preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       \\t: {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      \\t: {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   \\t: {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask \\t: {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   \\t: {text_preprocessed[\"input_type_ids\"][0, :12]}')\n",
    "\n",
    "# 3 Input BERT model need\n",
    "# 1. input_word_ids\n",
    "# 2. input_mask\n",
    "# 3. input_type_ids "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
      "Pooled Outputs Shape:(1, 768)\n",
      "Pooled Outputs Values:[-0.7612924  -0.15849979  0.5720426   0.43245652 -0.33294767 -0.08109941\n",
      "  0.5674548   0.10577297  0.29199526 -0.99840224  0.46006808  0.1845455 ]\n",
      "Sequence Outputs Shape:(1, 128, 768)\n",
      "Sequence Outputs Values:[[ 0.1378846   0.21694613  0.17518272 ... -0.00650308  0.22636311\n",
      "   0.22305849]\n",
      " [-0.43794012  0.2332033  -0.17401683 ... -0.12302686  1.3747523\n",
      "   0.35195723]\n",
      " [-0.132808    0.36113238  0.26082492 ...  0.17491016  0.78390354\n",
      "   0.50536287]\n",
      " ...\n",
      " [ 0.26680347  0.12717715 -0.45306003 ... -0.2467128   0.27201653\n",
      "   0.36186197]\n",
      " [-0.06213828  0.09613115 -0.06121171 ...  0.13682327  0.19195457\n",
      "   0.39893985]\n",
      " [-0.3652673   0.42820388 -0.32194316 ...  0.13237154  1.1129215\n",
      "   0.2600068 ]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')\n",
    "\n",
    "# BERT model return 3 outputs\n",
    "# 1. pooled_output : Represent the entire input sequence as a single vector (Embedding of the entire sequence)\n",
    "# 2. sequence_output : Represent contextual embedding for every token in the input sequence\n",
    "# 3. encoder_outputs : No idea what this is LMAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create & Fine-tune Classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wasin/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='RAW_TEXT_INPUT_LAYER')\n",
    "preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='BERT_PREPROCESSING_LAYER')\n",
    "encoder_inputs = preprocessing_layer(text_input)\n",
    "encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_ENCODER_LAYER')\n",
    "outputs = encoder(encoder_inputs)\n",
    "\n",
    "# Custom Network\n",
    "nn = outputs['pooled_output']\n",
    "nn = tf.keras.layers.Dropout(0.1)(nn)\n",
    "nn = tf.keras.layers.Dense(1, activation=None, name='CLASSIFIER')(nn)\n",
    "\n",
    "model = tf.keras.Model(text_input, nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  : ['this is the shittest movie I have ever digest into my brain']\n",
      "Output : [[0.4663]]\n"
     ]
    }
   ],
   "source": [
    "# Test run the model\n",
    "print(f'Input  : {text_test}')\n",
    "print(f'Output : {tf.sigmoid(model(tf.constant(text_test)))}')\n",
    "\n",
    "# Q: Why it got such a positive output?\n",
    "# A: Because the model is not trained yet, so the output is random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Plot the model with keras super cool plot function\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer function AdamW the original BERT optimizer\n",
    "\n",
    "optimizer = optimization.create_optimizer(\n",
    "    init_lr=3e-5, # Recommended by Tensorflow 5e-5, 3e-5, 2e-5\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    optimizer_type='adamw'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Callbacks\n",
    "\n",
    "# Tensorboard Callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs',\n",
    "    histogram_freq=1,\n",
    "    profile_batch=0\n",
    ")\n",
    "\n",
    "# Checkpoint Callback\n",
    "checkpoint_path = 'bert_imdb_sentiment_classifier.h5'\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_binary_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "625/625 [==============================] - 133s 212ms/step - loss: 0.0141 - binary_accuracy: 0.9959 - val_loss: 0.4971 - val_binary_accuracy: 0.8890\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 0.0149 - binary_accuracy: 0.9954 - val_loss: 0.4971 - val_binary_accuracy: 0.8890\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 129s 206ms/step - loss: 0.0146 - binary_accuracy: 0.9960 - val_loss: 0.4971 - val_binary_accuracy: 0.8890\n",
      "Epoch 9/10\n",
      "286/625 [============>.................] - ETA: 56s - loss: 0.0181 - binary_accuracy: 0.9951"
     ]
    }
   ],
   "source": [
    "# Take about 2min per epochs on PCI-E Nvidia A100 \n",
    "history = model.fit(initial_epoch=5, x=train_dataset, validation_data=validation_dataset, epochs=10, callbacks=[tensorboard_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  : Wow! This movie was a rollercoaster of emotions. The acting was superb, the plot was engaging, and the cinematography was breathtaking. I couldn't take my eyes off the screen!\n",
      "RawOut: [[0.998]]\n",
      "Output : 1\n",
      "Time   : 0.03455495834350586\n",
      "============================================================\n",
      "Input  : What a disappointment! The film had a promising premise, but it fell flat with weak execution. The characters were one-dimensional, and the plot was predictable. I expected more from such a hyped movie.\n",
      "RawOut: [[9.245e-05]]\n",
      "Output : 0\n",
      "Time   : 0.05763697624206543\n",
      "============================================================\n",
      "Input  : This movie exceeded all my expectations. The storyline was gripping, and the performances were Oscar-worthy. It's a must-watch for anyone who loves intense dramas.\n",
      "RawOut: [[1.]]\n",
      "Output : 1\n",
      "Time   : 0.0315401554107666\n",
      "============================================================\n",
      "Input  : I regret wasting my time on this film. The plot was confusing, and the pacing was all over the place. I struggled to connect with any of the characters, making it difficult to care about what was happening on screen.\n",
      "RawOut: [[0.0002632]]\n",
      "Output : 0\n",
      "Time   : 0.027965068817138672\n",
      "============================================================\n",
      "Input  : Incredible! This movie was a visual masterpiece. The special effects were mind-blowing, and the action sequences were adrenaline-pumping. I can't wait to see it again!\n",
      "RawOut: [[0.997]]\n",
      "Output : 1\n",
      "Time   : 0.02960371971130371\n",
      "============================================================\n",
      "Input  : I don't understand the hype around this movie. The dialogue was cheesy, and the acting was subpar. It felt like a generic, forgettable film that lacked any originality.\n",
      "RawOut: [[0.0001811]]\n",
      "Output : 0\n",
      "Time   : 0.04217100143432617\n",
      "============================================================\n",
      "Input  : A heartwarming and touching story that stayed with me long after the credits rolled. The performances were heartful and sincere, making it an emotionally enriching experience.\n",
      "RawOut: [[1.]]\n",
      "Output : 1\n",
      "Time   : 0.030060529708862305\n",
      "============================================================\n",
      "Input  : This movie was a disaster. The plot was riddled with holes, and the ending was unsatisfying. I found myself checking my watch repeatedly, wishing it would end sooner.\n",
      "RawOut: [[0.0001377]]\n",
      "Output : 0\n",
      "Time   : 0.041036367416381836\n",
      "============================================================\n",
      "Input  : A brilliant combination of humor and heart. The witty dialogue had me laughing out loud, and the characters were relatable and endearing. A feel-good movie at its finest!\n",
      "RawOut: [[0.999]]\n",
      "Output : 1\n",
      "Time   : 0.03409314155578613\n",
      "============================================================\n",
      "Input  : I can't believe I wasted money on this film. The acting was cringe-worthy, and the plot was a jumbled mess. I left the theater feeling frustrated and cheated.\n",
      "RawOut: [[0.0002288]]\n",
      "Output : 0\n",
      "Time   : 0.027973413467407227\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Test the model\n",
    "movie_reviews = [\n",
    "    \"Wow! This movie was a rollercoaster of emotions. The acting was superb, the plot was engaging, and the cinematography was breathtaking. I couldn't take my eyes off the screen!\",\n",
    "    \"What a disappointment! The film had a promising premise, but it fell flat with weak execution. The characters were one-dimensional, and the plot was predictable. I expected more from such a hyped movie.\",\n",
    "    \"This movie exceeded all my expectations. The storyline was gripping, and the performances were Oscar-worthy. It's a must-watch for anyone who loves intense dramas.\",\n",
    "    \"I regret wasting my time on this film. The plot was confusing, and the pacing was all over the place. I struggled to connect with any of the characters, making it difficult to care about what was happening on screen.\",\n",
    "    \"Incredible! This movie was a visual masterpiece. The special effects were mind-blowing, and the action sequences were adrenaline-pumping. I can't wait to see it again!\",\n",
    "    \"I don't understand the hype around this movie. The dialogue was cheesy, and the acting was subpar. It felt like a generic, forgettable film that lacked any originality.\",\n",
    "    \"A heartwarming and touching story that stayed with me long after the credits rolled. The performances were heartful and sincere, making it an emotionally enriching experience.\",\n",
    "    \"This movie was a disaster. The plot was riddled with holes, and the ending was unsatisfying. I found myself checking my watch repeatedly, wishing it would end sooner.\",\n",
    "    \"A brilliant combination of humor and heart. The witty dialogue had me laughing out loud, and the characters were relatable and endearing. A feel-good movie at its finest!\",\n",
    "    \"I can't believe I wasted money on this film. The acting was cringe-worthy, and the plot was a jumbled mess. I left the theater feeling frustrated and cheated.\"\n",
    "]\n",
    "\n",
    "\n",
    "for text in movie_reviews:\n",
    "    s = time.time()\n",
    "    output = tf.sigmoid(model(tf.constant([text])))\n",
    "    t = time.time() - s\n",
    "    print(f'Input  : {text}')\n",
    "    print(f'RawOut: {output}')\n",
    "    print(f'Output : {tf.where(output < 0.5, 0, 1)[0][0]}')\n",
    "    print(f'Time   : {t}')\n",
    "    print(\"============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
